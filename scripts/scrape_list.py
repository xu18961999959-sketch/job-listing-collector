#!/usr/bin/env python3
"""
æŠ“å–å…¬è€ƒé›·è¾¾èŒä½åˆ—è¡¨

è¾“å‡º: data/job_list_YYYYMMDD.json

ä½¿ç”¨æ–¹æ³•:
    python scripts/scrape_list.py [--date YYYY-MM-DD]
"""

import argparse
import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# é…ç½®
BASE_URL = "https://www.gongkaoleida.com"
LIST_URL = f"{BASE_URL}/area/878-0-0-0-124"  # æ±Ÿè‹çœ
DATA_DIR = Path(__file__).parent.parent / "data"

# ç­›é€‰è§„åˆ™
EXCLUDE_KEYWORDS = ["æˆç»©", "åå•", "é¢è¯•", "ä½“æ£€", "é¢†å–", "èµ„æ ¼å®¡æŸ¥", "å…¬ç¤º", "å½•ç”¨", "é€šçŸ¥"]
INCLUDE_KEYWORDS = ["æ‹›è˜", "æ‹›å‹Ÿ", "é€‰è˜", "æ‹›è€ƒ", "é´é€‰", "é€‰è°ƒ"]


def is_recruitment_post(title: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ‹›è˜å…¬å‘Š"""
    for keyword in EXCLUDE_KEYWORDS:
        if keyword in title:
            return False
    for keyword in INCLUDE_KEYWORDS:
        if keyword in title:
            return True
    return False


async def fetch_list(target_date: str) -> list:
    """ä½¿ç”¨ Playwright æŠ“å–èŒä½åˆ—è¡¨"""
    try:
        from playwright.async_api import async_playwright
    except ImportError:
        print("âŒ è¯·å®‰è£… playwright: pip install playwright && playwright install chromium")
        sys.exit(1)
    
    jobs = []
    print(f"ğŸ“‹ å¼€å§‹æŠ“å– {target_date} çš„æ‹›è˜ä¿¡æ¯...")
    print(f"ğŸŒ URL: {LIST_URL}")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        try:
            await page.goto(LIST_URL, timeout=60000)
            await page.wait_for_load_state("networkidle", timeout=30000)
            await asyncio.sleep(2)
            
            # è·å–æ‰€æœ‰é“¾æ¥
            links = await page.query_selector_all("a")
            
            for link in links:
                try:
                    href = await link.get_attribute("href")
                    title = await link.inner_text()
                    
                    if not title or len(title.strip()) < 10:
                        continue
                    if not href or href.startswith("#"):
                        continue
                    
                    title = title.strip()
                    
                    if not is_recruitment_post(title):
                        continue
                    
                    full_url = href if href.startswith("http") else f"{BASE_URL}{href}"
                    
                    jobs.append({
                        "title": title,
                        "url": full_url,
                        "date": target_date,
                        "source": ""
                    })
                except:
                    continue
            
        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        finally:
            await browser.close()
    
    # å»é‡
    seen = set()
    unique_jobs = []
    for job in jobs:
        if job["url"] not in seen:
            seen.add(job["url"])
            unique_jobs.append(job)
    
    print(f"âœ… æ‰¾åˆ° {len(unique_jobs)} æ¡æ‹›è˜å…¬å‘Š")
    return unique_jobs


def main():
    parser = argparse.ArgumentParser(description="æŠ“å–å…¬è€ƒé›·è¾¾èŒä½åˆ—è¡¨")
    parser.add_argument("--date", help="é‡‡é›†æ—¥æœŸ YYYY-MM-DD", 
                        default=os.environ.get("COLLECT_DATE", datetime.now().strftime("%Y-%m-%d")))
    args = parser.parse_args()
    
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    jobs = asyncio.run(fetch_list(args.date))
    
    if not jobs:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ‹›è˜å…¬å‘Š")
        return
    
    # ä¿å­˜
    date_str = args.date.replace("-", "")
    output_file = DATA_DIR / f"job_list_{date_str}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(jobs, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š èŒä½åˆ—è¡¨:")
    for i, job in enumerate(jobs[:10], 1):
        print(f"   {i}. {job['title'][:50]}...")
    if len(jobs) > 10:
        print(f"   ... å…± {len(jobs)} æ¡")


if __name__ == "__main__":
    main()

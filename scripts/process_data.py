#!/usr/bin/env python3
"""
å¤„ç†å¹¶åˆå¹¶é‡‡é›†æ•°æ®

è¯»å–: data/job_list_*.json, data/temp_details.json
è¾“å‡º: data/gongkaoleida_YYYYMMDD.json
"""

import glob
import json
import re
from datetime import datetime
from pathlib import Path

DATA_DIR = Path(__file__).parent.parent / "data"


def extract_salary(text: str) -> str:
    """æå–è–ªèµ„ä¿¡æ¯"""
    patterns = [
        r'(å¹´è–ª[ï¼š:]\s*\d+(?:-\d+)?ä¸‡)',
        r'(æœˆè–ª[ï¼š:]\s*\d+(?:-\d+)?[åƒå…ƒkK])',
        r'(\d+(?:-\d+)?ä¸‡/å¹´)',
        r'(\d+(?:-\d+)?[åƒkK]/æœˆ)',
        r'(å·¥èµ„[ï¼š:]\s*\d+(?:-\d+)?å…ƒ)',
        r'(\d+(?:-\d+)?(?:k|K|ä¸‡|å…ƒ)(?:/æœˆ|/å¹´)?)',
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1)
    return "æœªå…¬å¼€"


def extract_count(text: str) -> str:
    """æå–æ‹›è˜äººæ•°"""
    patterns = [
        r'æ‹›è˜[äººæ•°]*[ï¼š:\s]*(\d+)\s*[äººå]',
        r'æ‹›å½•[äººæ•°]*[ï¼š:\s]*(\d+)\s*[äººå]',
        r'æ‹Ÿæ‹›[è˜å½•]*\s*(\d+)\s*[äººå]',
        r'æ‹›è˜å²—ä½\s*(\d+)\s*ä¸ª',
        r'åé¢[ï¼š:]\s*(\d+)',
        r'å…±[æ‹›è˜å½•]*\s*(\d+)\s*[äººå]',
        r'æ‹›\s*(\d+)\s*äºº',
        r'(\d+)\s*ä¸ªå²—ä½',
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return f"{match.group(1)}äºº"
    return "è‹¥å¹²"


def extract_education(text: str) -> str:
    """æå–å­¦å†è¦æ±‚"""
    patterns = [
        r'å­¦å†[è¦æ±‚ï¼š:]*\s*(é«˜ä¸­|ä¸­ä¸“|å¤§ä¸“|æœ¬ç§‘|ç¡•å£«|åšå£«|ç ”ç©¶ç”Ÿ)(?:åŠä»¥ä¸Š|ä»¥ä¸Š|å­¦å†)?',
        r'(å…¨æ—¥åˆ¶æœ¬ç§‘|å…¨æ—¥åˆ¶ç¡•å£«|å…¨æ—¥åˆ¶åšå£«|å…¨æ—¥åˆ¶ç ”ç©¶ç”Ÿ)',
        r'(æœ¬ç§‘åŠä»¥ä¸Š|ç¡•å£«åŠä»¥ä¸Š|åšå£«åŠä»¥ä¸Š|å¤§ä¸“åŠä»¥ä¸Š)',
        r'(æœ¬ç§‘|ç¡•å£«|åšå£«|ç ”ç©¶ç”Ÿ|å¤§ä¸“|é«˜ä¸­|ä¸­ä¸“)(?:åŠä»¥ä¸Š|ä»¥ä¸Š|å­¦å†)',
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            result = match.group(1) if match.lastindex else match.group(0)
            return result
    
    # ç®€å•åŒ¹é…
    if "åšå£«" in text:
        return "åšå£«"
    if "ç¡•å£«" in text or "ç ”ç©¶ç”Ÿ" in text:
        return "ç¡•å£«åŠä»¥ä¸Š"
    if "æœ¬ç§‘" in text:
        return "æœ¬ç§‘åŠä»¥ä¸Š"
    if "å¤§ä¸“" in text:
        return "å¤§ä¸“åŠä»¥ä¸Š"
    
    return "è¯¦è§å…¬å‘Š"


def extract_deadline(text: str) -> str:
    """æå–æŠ¥åæˆªæ­¢æ—¥æœŸ"""
    patterns = [
        r'æŠ¥å[æ—¶é—´æˆªæ­¢]*[ï¼š:è‡³åˆ°]*\s*(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'æˆªæ­¢[æ—¶é—´æ—¥æœŸ]*[ï¼š:è‡³åˆ°]*\s*(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'æŠ¥å.*?è‡³.*?(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'(\d{4}-\d{1,2}-\d{1,2}).*?(?:æˆªæ­¢|ç»“æŸ)',
        r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1)
    return "è¯¦è§å…¬å‘Š"


def extract_location(text: str, title: str = "") -> str:
    """æå–å·¥ä½œåœ°ç‚¹"""
    combined = title + " " + text
    
    # æ±Ÿè‹çœåŸå¸‚åˆ—è¡¨
    cities = {
        "å—äº¬": "å—äº¬å¸‚",
        "è‹å·": "è‹å·å¸‚", 
        "æ— é”¡": "æ— é”¡å¸‚",
        "å¸¸å·": "å¸¸å·å¸‚",
        "å—é€š": "å—é€šå¸‚",
        "æ‰¬å·": "æ‰¬å·å¸‚",
        "é•‡æ±Ÿ": "é•‡æ±Ÿå¸‚",
        "æ³°å·": "æ³°å·å¸‚",
        "å¾å·": "å¾å·å¸‚",
        "ç›åŸ": "ç›åŸå¸‚",
        "æ·®å®‰": "æ·®å®‰å¸‚",
        "è¿äº‘æ¸¯": "è¿äº‘æ¸¯å¸‚",
        "å®¿è¿": "å®¿è¿å¸‚",
        "æ˜†å±±": "è‹å·å¸‚æ˜†å±±",
        "å¼ å®¶æ¸¯": "è‹å·å¸‚å¼ å®¶æ¸¯",
        "å¸¸ç†Ÿ": "è‹å·å¸‚å¸¸ç†Ÿ",
        "æ±Ÿé˜´": "æ— é”¡å¸‚æ±Ÿé˜´",
        "å®œå…´": "æ— é”¡å¸‚å®œå…´",
    }
    
    for city, full_name in cities.items():
        if city in combined:
            return f"æ±Ÿè‹çœ{full_name}"
    
    return "æ±Ÿè‹çœ"


def extract_employer(text: str, title: str = "") -> str:
    """æå–æ‹›è˜å•ä½"""
    patterns = [
        r'æ‹›è˜å•ä½[ï¼š:]\s*([^\n,ï¼Œ]{2,30})',
        r'ç”¨äººå•ä½[ï¼š:]\s*([^\n,ï¼Œ]{2,30})',
        r'ä¸»ç®¡å•ä½[ï¼š:]\s*([^\n,ï¼Œ]{2,30})',
        r'ä¸»åŠ[å•ä½]*[ï¼š:]\s*([^\n,ï¼Œ]{2,30})',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
    
    # ä»æ ‡é¢˜æå–
    # å¦‚ "2026å¹´å—äº¬å¸‚XXXæ‹›è˜å…¬å‘Š" -> "å—äº¬å¸‚XXX"
    match = re.search(r'(\d{4}å¹´)?(.{2,20}?)(å…¬å¼€)?æ‹›[è˜å½•]', title)
    if match:
        employer = match.group(2).strip()
        if len(employer) >= 4:
            return employer
    
    return ""


def main():
    today_str = datetime.now().strftime("%Y%m%d")
    
    # åŠ è½½èŒä½åˆ—è¡¨
    list_files = sorted(DATA_DIR.glob("job_list_*.json"), reverse=True)
    if not list_files:
        print("âŒ æœªæ‰¾åˆ°èŒä½åˆ—è¡¨æ–‡ä»¶")
        return
    
    job_list = []
    for f in list_files[:1]:  # åªå–æœ€æ–°çš„
        with open(f, "r", encoding="utf-8") as fp:
            job_list = json.load(fp)
    
    print(f"ğŸ“‹ åŠ è½½èŒä½åˆ—è¡¨: {len(job_list)} æ¡")
    
    # åŠ è½½è¯¦æƒ…
    details_file = DATA_DIR / "temp_details.json"
    details = []
    if details_file.exists():
        with open(details_file, "r", encoding="utf-8") as f:
            details = json.load(f)
    
    print(f"ğŸ“„ åŠ è½½è¯¦æƒ…: {len(details)} æ¡")
    
    # å»ºç«‹ URL -> è¯¦æƒ… æ˜ å°„
    detail_map = {d["url"]: d for d in details}
    
    # åˆå¹¶å¤„ç†
    results = []
    for job in job_list:
        url = job.get("url", "")
        detail = detail_map.get(url, {})
        content = detail.get("content", "") or ""
        title = job.get("title", detail.get("title", ""))
        
        # æå–æ‹›è˜å•ä½
        employer = job.get("source", "") or extract_employer(content, title)
        
        processed = {
            "èŒä½åç§°": title or "æœªçŸ¥èŒä½",
            "æ‹›è˜å•ä½": employer,
            "è–ªèµ„èŒƒå›´": extract_salary(content),
            "å·¥ä½œåœ°ç‚¹": extract_location(content, title),
            "å‘å¸ƒæ—¥æœŸ": job.get("date", datetime.now().strftime("%Y-%m-%d")),
            "æ¥æºç½‘ç«™": "å…¬è€ƒé›·è¾¾",
            "åŸæ–‡é“¾æ¥": url,
            "èŒä½æè¿°": content[:2000] if content else "",
            "æ‹›è˜äººæ•°": extract_count(content),
            "å­¦å†è¦æ±‚": extract_education(content),
            "æŠ¥åæˆªæ­¢": extract_deadline(content),
            "é‡‡é›†æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        results.append(processed)
    
    # ä¿å­˜
    output_file = DATA_DIR / f"gongkaoleida_{today_str}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å¤„ç†å®Œæˆ: {len(results)} æ¡")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # æ‰“å°ç¤ºä¾‹
    if results:
        print(f"\nğŸ“Š ç¤ºä¾‹æ•°æ®:")
        sample = results[0]
        print(f"   èŒä½: {sample['èŒä½åç§°'][:40]}")
        print(f"   å•ä½: {sample['æ‹›è˜å•ä½']}")
        print(f"   äººæ•°: {sample['æ‹›è˜äººæ•°']}")
        print(f"   å­¦å†: {sample['å­¦å†è¦æ±‚']}")
        print(f"   æˆªæ­¢: {sample['æŠ¥åæˆªæ­¢']}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if details_file.exists():
        details_file.unlink()
        print("ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")


if __name__ == "__main__":
    main()

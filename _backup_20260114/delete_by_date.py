#!/usr/bin/env python3
"""
åˆ é™¤ Notion æ•°æ®åº“ä¸­æŒ‡å®šæ—¥æœŸçš„è®°å½•
"""
import os
import sys
import json
import requests

NOTION_API_URL = "https://api.notion.com/v1"
NOTION_VERSION = "2022-06-28"
DATABASE_ID = "2e07d626c84e81a5b57fea92a936e2cd"

def main():
    token = os.environ.get("NOTION_TOKEN")
    if not token:
        print("âŒ è¯·è®¾ç½® NOTION_TOKEN ç¯å¢ƒå˜é‡")
        return
    
    # ä»JSONæ–‡ä»¶è¯»å–è¦åˆ é™¤çš„URLåˆ—è¡¨
    json_file = sys.argv[1] if len(sys.argv) > 1 else "data/gongkaoleida_20260112.json"
    
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            jobs = json.load(f)
        urls_to_delete = [job["åŸæ–‡é“¾æ¥"] for job in jobs]
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_VERSION
    }
    
    print(f"ğŸ” å‡†å¤‡åˆ é™¤ {len(urls_to_delete)} æ¡è®°å½•...")
    
    deleted_count = 0
    for i, url in enumerate(urls_to_delete, 1):
        # æŸ¥è¯¢åŒ…å«è¯¥URLçš„é¡µé¢
        query_url = f"{NOTION_API_URL}/databases/{DATABASE_ID}/query"
        query_data = {
            "filter": {
                "property": "åŸæ–‡é“¾æ¥",
                "url": {"equals": url}
            }
        }
        
        try:
            response = requests.post(query_url, headers=headers, json=query_data)
            if response.status_code == 200:
                results = response.json().get("results", [])
                for page in results:
                    page_id = page["id"]
                    title_list = page.get("properties", {}).get("èŒä½åç§°", {}).get("title", [])
                    title = title_list[0].get("plain_text", "æœªçŸ¥") if title_list else "æœªçŸ¥"
                    
                    # åˆ é™¤ï¼ˆå½’æ¡£ï¼‰é¡µé¢
                    archive_url = f"{NOTION_API_URL}/pages/{page_id}"
                    archive_data = {"archived": True}
                    del_response = requests.patch(archive_url, headers=headers, json=archive_data)
                    
                    if del_response.status_code == 200:
                        print(f"  [{i}/{len(urls_to_delete)}] âœ… å·²åˆ é™¤: {title[:35]}...")
                        deleted_count += 1
                    else:
                        print(f"  [{i}/{len(urls_to_delete)}] âŒ åˆ é™¤å¤±è´¥: {title[:35]}...")
            else:
                print(f"  [{i}/{len(urls_to_delete)}] âŒ æŸ¥è¯¢å¤±è´¥")
        except Exception as e:
            print(f"  [{i}/{len(urls_to_delete)}] âŒ é”™è¯¯: {e}")
    
    print(f"\nğŸ‰ åˆ é™¤å®Œæˆ! å…±åˆ é™¤ {deleted_count} æ¡è®°å½•")

if __name__ == "__main__":
    main()
